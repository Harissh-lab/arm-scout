# ğŸ¯ COMPLETE WORKFLOW - Train AI Here, Deploy to Pi

Complete step-by-step guide for training on Windows and deploying to Raspberry Pi.

---

## ğŸ“‹ Overview

```
Your Windows PC          â†’         Raspberry Pi
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
1. Train AI model        â†’    4. Pull trained model
2. Test model locally    â†’    5. Run detection API
3. Push to Git           â†’    6. Stream camera feed
                         â†’    7. Detect hazards live!
```

---

## ğŸ–¥ï¸ PART 1: Train on Your Windows PC

### Step 1: Install Dependencies

**Double-click:** `setup.bat`

Or manually:
```powershell
pip install ultralytics torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
pip install opencv-python flask flask-cors numpy pillow
```

### Step 2: Prepare Dataset

Your dataset should be in YOLO format. Create this structure:

```
dataset/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ images/
â”‚   â”‚   â”œâ”€â”€ road_001.jpg
â”‚   â”‚   â”œâ”€â”€ road_002.jpg
â”‚   â”‚   â””â”€â”€ ... (80% of your images)
â”‚   â””â”€â”€ labels/
â”‚       â”œâ”€â”€ road_001.txt
â”‚       â”œâ”€â”€ road_002.txt
â”‚       â””â”€â”€ ... (matching .txt files)
â”œâ”€â”€ val/
â”‚   â”œâ”€â”€ images/
â”‚   â”‚   â””â”€â”€ ... (20% of your images)
â”‚   â””â”€â”€ labels/
â”‚       â””â”€â”€ ... (matching .txt files)
```

**Label format** (YOLO .txt):
```
class_id center_x center_y width height
```

**Classes:**
- 0 = debris
- 1 = pothole
- 2 = roadblock
- 3 = accident
- 4 = flood
- 5 = construction

All values normalized 0-1.

### Step 3: Train Model

**Double-click:** `train.bat`

Or manually:
```powershell
python train.py
```

**What happens:**
- Downloads YOLOv8n pretrained model (~6 MB)
- Trains on your dataset
- Saves to `hazard-detection/road-hazards-v1/weights/best.pt`
- Generates training metrics and graphs

**Estimated time:**
- 500 images: 30-60 min (CPU) / 10-15 min (GPU)
- 2000 images: 2-4 hours (CPU) / 30-60 min (GPU)

### Step 4: Test Model

**Double-click:** `test.bat`

Or manually:
```powershell
python test_model.py
```

**Testing options:**
1. Single image - Test on one photo
2. Folder - Test on multiple photos
3. Webcam - Live detection from your camera

### Step 5: Verify Results

Check training results:
```
hazard-detection/road-hazards-v1/
â”œâ”€â”€ weights/
â”‚   â”œâ”€â”€ best.pt       â­ YOUR TRAINED MODEL
â”‚   â””â”€â”€ last.pt
â”œâ”€â”€ results.png       ğŸ“ˆ Training graphs
â”œâ”€â”€ confusion_matrix.png
â””â”€â”€ ...
```

**Good model indicators:**
- Loss decreasing over epochs
- mAP (mean Average Precision) > 0.7
- Confusion matrix shows good classification

---

## ğŸš€ PART 2: Deploy to Raspberry Pi

### Option A: Via Git (Recommended)

**On your PC:**
```powershell
git add .
git commit -m "Added trained hazard detection model"
git push origin main
```

**On Raspberry Pi:**
```bash
git pull origin main
```

### Option B: Direct Copy

**From your PC:**
```powershell
# Copy model file to Pi
scp hazard-detection/road-hazards-v1/weights/best.pt pi@raspberrypi.local:~/hazard-scout/

# Or copy entire project
scp -r "Hazard Scout Prototype Design (Copy)" pi@raspberrypi.local:~/
```

---

## ğŸ“ PART 3: Setup Raspberry Pi

### Step 1: Install Dependencies on Pi

```bash
# On Raspberry Pi
ssh pi@raspberrypi.local

# Navigate to project
cd ~/hazard-scout/

# Install Python dependencies
pip3 install ultralytics torch torchvision opencv-python flask flask-cors

# Install Motion (for camera streaming)
sudo apt-get update
sudo apt-get install motion

# Install Node.js dependencies (for web app)
npm install
```

### Step 2: Configure Motion (Camera Stream)

```bash
sudo nano /etc/motion/motion.conf
```

**Key settings:**
```conf
daemon on
stream_port 8080
stream_localhost off
stream_auth_method 0
webcontrol_localhost off
framerate 15
width 640
height 480
```

**Start Motion:**
```bash
sudo systemctl enable motion
sudo systemctl start motion

# Verify camera stream
curl http://localhost:8080
```

### Step 3: Run Detection API

```bash
python3 detection_api.py
```

Should see:
```
âœ… Model loaded successfully!
ğŸŒ Server running at: http://localhost:5000
```

### Step 4: Run Web App

```bash
# In another terminal
npm run dev
```

App runs at: `http://localhost:3000`

---

## ğŸ“± PART 4: Configure App

### On Web App:

1. Open `http://[PI-IP]:3000` in browser
2. Navigate to **Safety Scout** tab
3. Click **Settings** (gear icon)
4. Configure Pi Camera:
   - **Camera Stream URL**: `http://[PI-IP]:8080`
   - **API Endpoint**: `http://[PI-IP]:5000/api`
5. Click **Save Camera Settings**

### Test Detection:

1. Grant GPS permission when prompted
2. Toggle **Camera Detection** ON
3. You should see:
   - âœ… Live camera feed
   - âœ… Speed display
   - âœ… GPS coordinates
   - âœ… Real-time hazard detection!

---

## ğŸ”„ Complete Workflow Commands

### On Your Windows PC:

```powershell
# 1. Setup and install
setup.bat

# 2. Add your dataset to dataset/ folder

# 3. Train model
train.bat

# 4. Test model
test.bat

# 5. Push to Git
git add .
git commit -m "Trained hazard detection model"
git push
```

### On Raspberry Pi:

```bash
# 1. Pull latest code
git pull

# 2. Install dependencies
pip3 install ultralytics torch torchvision opencv-python flask flask-cors
npm install

# 3. Start camera stream
sudo systemctl start motion

# 4. Terminal 1: Run detection API
python3 detection_api.py

# 5. Terminal 2: Run web app
npm run dev
```

### Configure in Browser:

1. Open `http://[PI-IP]:3000`
2. Settings â†’ Configure camera URLs
3. Toggle Camera Detection ON
4. âœ… Done!

---

## ğŸ“Š Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  WINDOWS PC (Training)                          â”‚
â”‚  â”œâ”€â”€ Dataset (your images)                      â”‚
â”‚  â”œâ”€â”€ train.py â†’ Trained model (best.pt)         â”‚
â”‚  â””â”€â”€ Push to Git                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RASPBERRY PI (Deployment)                      â”‚
â”‚  â”œâ”€â”€ Motion Server (port 8080) â†’ Camera Stream  â”‚
â”‚  â”œâ”€â”€ Detection API (port 5000) â†’ AI Detection   â”‚
â”‚  â””â”€â”€ Web App (port 3000) â†’ User Interface       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  USER BROWSER                                   â”‚
â”‚  â”œâ”€â”€ Live camera feed                           â”‚
â”‚  â”œâ”€â”€ Real-time hazard detection                 â”‚
â”‚  â”œâ”€â”€ GPS tracking                               â”‚
â”‚  â””â”€â”€ Proximity alerts                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Expected Performance

### Model Accuracy (after good training):
- Debris: 85-95%
- Pothole: 80-90%
- Roadblock: 90-95%

### Inference Speed:
- Raspberry Pi 4: 100-200ms per frame
- With optimization: 50-100ms

### Web App:
- Real-time GPS tracking
- 500m proximity alerts
- Instant notifications

---

## ğŸ› Troubleshooting

### Windows Training Issues:

**"Out of memory"**
```python
# Edit train.py, reduce batch size
'batch': 4,  # Instead of 16
```

**"No images found"**
- Check dataset/train/images/ has your images
- Check dataset/val/images/ has validation images

**"CUDA not available" (GPU not detected)**
- This is normal if you don't have NVIDIA GPU
- Training will use CPU (slower but works)

### Raspberry Pi Issues:

**Camera stream not working**
```bash
# Check Motion status
sudo systemctl status motion

# Check camera connection
vcgencmd get_camera

# Expected: supported=1 detected=1
```

**API not starting**
```bash
# Check if model exists
ls -la hazard-detection/road-hazards-v1/weights/best.pt

# Check Python packages
pip3 list | grep ultralytics
```

**App not loading**
```bash
# Check if Node.js installed
node --version

# Reinstall dependencies
rm -rf node_modules
npm install
```

---

## âœ… Success Checklist

### Windows PC:
- [ ] Dependencies installed (`setup.bat`)
- [ ] Dataset prepared (images + labels)
- [ ] Model trained successfully (`train.bat`)
- [ ] Model tested (`test.bat`)
- [ ] Results look good (check confusion matrix)
- [ ] Pushed to Git

### Raspberry Pi:
- [ ] Code pulled from Git
- [ ] Python dependencies installed
- [ ] Motion server running (camera stream at :8080)
- [ ] Detection API running (:5000)
- [ ] Web app running (:3000)
- [ ] Camera URLs configured in app

### Final Test:
- [ ] Camera feed visible in monitoring screen
- [ ] GPS tracking working
- [ ] Hazards detected in real-time
- [ ] Proximity alerts appear
- [ ] All systems green! ğŸ‰

---

## ğŸ“š Quick Reference

### Files Created:
- `data.yaml` - Dataset configuration
- `train.py` - Training script
- `test_model.py` - Testing script
- `detection_api.py` - Flask API server
- `setup.bat` - Install dependencies
- `train.bat` - Start training
- `test.bat` - Test model
- `api.bat` - Start API server

### Folders:
- `dataset/` - Your training data
- `hazard-detection/` - Training results
- `src/` - Web application

### Guides:
- `TRAIN_HERE.md` - Local training guide
- `AI_TRAINING_GUIDE.md` - Detailed AI guide
- `RASPBERRY_PI_SETUP.md` - Pi hardware setup
- `CONFIGURATION.md` - Config reference
- This file - Complete workflow

---

## ğŸ“ Tips for Best Results

1. **Dataset Quality**
   - 1000+ images per class recommended
   - Varied lighting conditions
   - Different angles and distances
   - Balanced classes

2. **Training**
   - Start with 100 epochs
   - Monitor loss - should decrease
   - Check mAP - should increase
   - Use validation set (20% of data)

3. **Pi Optimization**
   - Use YOLOv8n (nano) for speed
   - Reduce image size if needed
   - Monitor CPU temperature
   - Consider overclocking for better performance

4. **Production**
   - Use systemd to auto-start services
   - Set up error logging
   - Monitor detection accuracy
   - Regular model retraining with new data

---

**You're all set! Train here, deploy to Pi, detect hazards! ğŸš€**
